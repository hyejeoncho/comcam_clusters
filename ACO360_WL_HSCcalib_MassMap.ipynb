{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f950321-79bb-4264-b2fd-9ef7595456a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:54:09.363845Z",
     "iopub.status.busy": "2025-02-27T16:54:09.363572Z",
     "iopub.status.idle": "2025-02-27T16:54:09.366100Z",
     "shell.execute_reply": "2025-02-27T16:54:09.365703Z",
     "shell.execute_reply.started": "2025-02-27T16:54:09.363830Z"
    }
   },
   "source": [
    "# Mass Map around Abell 360\n",
    "\n",
    "Anthony Englert\\\n",
    "LSST Science Piplines version: Weekly 2025_09\\\n",
    "Container Size: large\n",
    "\n",
    "This notebook is a first attempt at building a mass map of Abell 360 cluster from ComCam data, with the following main steps:\n",
    "\n",
    "- Loading the relevant object catalogs (all tracts and patches needed) using the butler\n",
    "- Color cut source selection\n",
    "- HSC lensing quality cuts\n",
    "- HSC calibration step. You will need to run the `gen_hsc_calibration` script outside of this notebook. The script is publicly available at: [https://github.com/PrincetonUniversity/hsc-y1-shear-calib](https://github.com/PrincetonUniversity/hsc-y1-shear-calib)\n",
    "- Computing mass map from calibrated shapes\n",
    "\n",
    "The first portion of this borrows from Celine's script to select galaxies redder than the red-sequence, then uses code developed for the Local Volume Complete Cluster Survey to compute the mass map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34840e55-4119-4612-a769-a808b6e97d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b109a-0868-43f6-8abc-36a915f69c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.daf.butler import Butler\n",
    "import lsst.geom as geom\n",
    "import lsst.afw.geom as afwGeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38325d14-740b-43ec-9b3c-79d820890543",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = '/repo/main'\n",
    "collection = 'LSSTComCam/runs/DRP/DP1/w_2025_08/DM-49029'\n",
    "butler = Butler(repo, collections=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19d115-4e0a-460d-a2eb-74dbf31fc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = butler.get('skyMap', skymap='lsst_cells_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de23f3-6156-4367-aa81-f024882dd2f3",
   "metadata": {},
   "source": [
    "## Find tracts and patches for Abell 360 and load the catalogs\n",
    "\n",
    "Find all the tracts/patches that falls in a given region around the A360 BCG, and store the results in a dictionary `tp_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68864e5c-d7b7-40db-b564-8e189894346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position of the BCG for A360\n",
    "ra_bcg = 37.862\n",
    "dec_bcg = 6.98\n",
    "\n",
    "# Looking for all patches in delta deg region around it\n",
    "delta = 0.5\n",
    "center = geom.SpherePoint(ra_bcg, dec_bcg, geom.degrees)\n",
    "ra_min, ra_max = ra_bcg - delta, ra_bcg + delta\n",
    "dec_min, dec_max = dec_bcg - delta, dec_bcg + delta\n",
    "\n",
    "ra_range = (ra_min, ra_max)\n",
    "dec_range = (dec_min, dec_max)\n",
    "radec = [geom.SpherePoint(ra_range[0], dec_range[0], geom.degrees),\n",
    "         geom.SpherePoint(ra_range[0], dec_range[1], geom.degrees),\n",
    "         geom.SpherePoint(ra_range[1], dec_range[0], geom.degrees),\n",
    "         geom.SpherePoint(ra_range[1], dec_range[1], geom.degrees)]\n",
    "\n",
    "tracts_and_patches = skymap.findTractPatchList(radec)\n",
    "\n",
    "tp_dict = {}\n",
    "for tract_num in np.arange(len(tracts_and_patches)):\n",
    "    tract_info = tracts_and_patches[tract_num][0]\n",
    "    tract_idx = tract_info.getId()\n",
    "    # All the patches around the cluster\n",
    "    patches = []\n",
    "    for i,patch in enumerate(tracts_and_patches[tract_num][1]):\n",
    "        patch_info = tracts_and_patches[tract_num][1][i]\n",
    "        patch_idx = patch_info.sequential_index\n",
    "        patches.append(patch_idx)\n",
    "    tp_dict.update({tract_idx:patches})\n",
    "#tp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9523bf59-d30d-49fb-bb1c-02ace8a32992",
   "metadata": {},
   "source": [
    "Load the object catalogs for all these tracts/patches, make basic cuts, and store in a single merged catalog `merged_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d1ef1-6b25-4e1a-9a27-0211cdc5a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the object catlaog of these patches\n",
    "datasetType = 'objectTable'\n",
    "#datasetType = 'deepCoadd_obj'\n",
    "merged_cat = pd.DataFrame()\n",
    "\n",
    "for tract in tp_dict.keys():\n",
    "    print(f'Loading objects from tract {tract}, patches:{tp_dict[tract]}')\n",
    "    for patch in tp_dict[tract]:\n",
    "        dataId = {'tract': tract, 'patch' : patch ,'skymap':'lsst_cells_v1'}\n",
    "        obj_cat = butler.get(datasetType, dataId=dataId)\n",
    "        filt = obj_cat['detect_isPrimary']==True\n",
    "        filt &= obj_cat['r_cModel_flag']== False\n",
    "        filt &= obj_cat['i_cModel_flag']== False\n",
    "        filt &= obj_cat['r_cModelFlux']>0\n",
    "        filt &= obj_cat['i_cModelFlux']>0\n",
    "        filt &= obj_cat['refExtendedness'] > 0.5\n",
    "\n",
    "        merged_cat = pd.concat([merged_cat, obj_cat[filt]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c09d4-b618-4746-af0c-324e325471a0",
   "metadata": {},
   "source": [
    "## Red sequence identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df7eeb-88b3-463c-ba8e-1eeff5a440a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:09:33.227567Z",
     "iopub.status.busy": "2025-03-11T08:09:33.226937Z",
     "iopub.status.idle": "2025-03-11T08:09:33.229610Z",
     "shell.execute_reply": "2025-03-11T08:09:33.229178Z",
     "shell.execute_reply.started": "2025-03-11T08:09:33.227548Z"
    }
   },
   "source": [
    "### Select a circular field close (<0.1 deg) to the BCG in order to identify RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72749b-f31b-4e4c-8037-4754f63277fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "c1 = SkyCoord(merged_cat['coord_ra'].values*u.deg, merged_cat['coord_dec'].values*u.deg)\n",
    "c2 = SkyCoord(ra_bcg*u.deg, dec_bcg*u.deg)\n",
    "sep = c1.separation(c2)\n",
    "\n",
    "sep.deg\n",
    "filt = sep.deg < 0.1 # stay close to cluster center for RS indentification\n",
    "merged_cat_rs = merged_cat[filt] # catalog for RS identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bddeb-a247-4164-bcdb-20850d761847",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_cat), len(merged_cat_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d04d17-6909-42d6-8528-c16016c3487d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:09:09.316496Z",
     "iopub.status.busy": "2024-12-10T10:09:09.316212Z",
     "iopub.status.idle": "2024-12-10T10:09:09.321215Z",
     "shell.execute_reply": "2024-12-10T10:09:09.318432Z",
     "shell.execute_reply.started": "2024-12-10T10:09:09.316483Z"
    }
   },
   "source": [
    "### Convert fluxes to magnitudes and identify red sequence in r-i versus r\n",
    "\n",
    "Conversion from fluxes to mag using formula from DP0.2 tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210781e-d08f-489c-9876-81ca1aba6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_i = -2.50 * np.log10(merged_cat_rs['i_cModelFlux']) + 31.4\n",
    "mag_r = -2.50 * np.log10(merged_cat_rs['r_cModelFlux']) + 31.4\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\n",
    "ax[0].hist(mag_r, bins=50)\n",
    "ax[1].hist(mag_i, bins=50)\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda95fc-5e57-4d06-84d5-9c01b2a6a17d",
   "metadata": {},
   "source": [
    "### Color magnitude diagram and by eye indetification of the red sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab9eff-f4ff-4aa5-89fb-014da9d5c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r, mag_r-mag_i, marker='.', s=0.3)\n",
    "ax.set_ylim([-2,2])\n",
    "ax.set_xlim([19,25])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')\n",
    "ax.plot([19,24],[0.4,0.3], color='r', linewidth=0.7)\n",
    "ax.plot([19,24],[0.6,0.5], color='r', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a4db6-9b71-4c44-8bd9-3dc775a0875c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:13:37.716333Z",
     "iopub.status.busy": "2025-03-11T08:13:37.715720Z",
     "iopub.status.idle": "2025-03-11T08:13:37.718367Z",
     "shell.execute_reply": "2025-03-11T08:13:37.717968Z",
     "shell.execute_reply.started": "2025-03-11T08:13:37.716316Z"
    }
   },
   "source": [
    "### Filter to identify red sequence galaxies in the sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5eeca9-03e8-484f-9aea-02b33ea1fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_hi = 0.6 - (0.1/5.) * (mag_r-19)\n",
    "rs_low = 0.4 - (0.1/5.)* (mag_r-19)\n",
    "color = mag_r - mag_i\n",
    "\n",
    "idx = np.where(np.logical_and(color>rs_low, color<rs_hi))[0]\n",
    "idx2 = np.where(mag_r.iloc[idx] < 23)[0] # keep the brightest objects only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638867fe-f9d1-4426-828c-d6b7132c918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r, mag_r-mag_i, marker='.', s=0.3) # all galaxies  \n",
    "ax.scatter(mag_r.iloc[idx].iloc[idx2], \n",
    "           mag_r.iloc[idx].iloc[idx2]-mag_i.iloc[idx].iloc[idx2], \n",
    "           marker='.', s=0.3) #red sequence galaxies\n",
    "ax.set_ylim([-2,2])\n",
    "ax.set_xlim([19,27])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')\n",
    "ax.plot([19,24],[0.4,0.3], color='r', linewidth=0.7)\n",
    "ax.plot([19,24],[0.6,0.5], color='r', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c23e9-caf3-42bd-ac24-374f6fbee153",
   "metadata": {},
   "source": [
    "## Remove red sequence galaxies in the full field\n",
    "\n",
    "For the analysis, we'll keep source galaxies within 0.5 deg from the BCG. Now we apply the RS cut defined on the small region above to the full field of the analysis. The RS-free catalog is stored as `merged_cat_wl`. The lensing quality cuts will be performed in a subsequent step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c83a6-a33f-412a-a34a-3e54fe9721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = sep.deg < 0.5 # larger field for analysis\n",
    "merged_cat_wl = merged_cat[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395f01c-04c5-4bbe-bdda-7bef379331ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_i = -2.50 * np.log10(merged_cat_wl['i_cModelFlux']) + 31.4\n",
    "mag_r = -2.50 * np.log10(merged_cat_wl['r_cModelFlux']) + 31.4\n",
    "color = mag_r - mag_i\n",
    "\n",
    "# Filter defined above applied to the full sample\n",
    "rs_hi = 0.6 - (0.1/5.) * (mag_r-19)\n",
    "rs_low = 0.4 - (0.1/5.)* (mag_r-19)\n",
    "\n",
    "idx = np.where(np.logical_and(color>rs_low, color<rs_hi))[0]\n",
    "idx2 = np.where(mag_r.iloc[idx] < 23)[0] # keep the brightest objects only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc7359-5f3d-4498-aefb-5a00cf34c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r, mag_r-mag_i, marker='.', s=0.3) # all galaxies  \n",
    "ax.scatter(mag_r.iloc[idx].iloc[idx2], \n",
    "           mag_r.iloc[idx].iloc[idx2]-mag_i.iloc[idx].iloc[idx2], \n",
    "           marker='.', s=0.3) #red sequence galaxies\n",
    "ax.set_ylim([-2,2])\n",
    "ax.set_xlim([19,27])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')\n",
    "ax.plot([19,24],[0.4,0.3], color='r', linewidth=0.7)\n",
    "ax.plot([19,24],[0.6,0.5], color='r', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56544c-49a5-4f5f-a61e-ed8d1caf02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_id_list = merged_cat_wl['objectId'].iloc[idx].iloc[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3236a-398e-47d5-9e7d-1e4bc4e38b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RS_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33932b2e-f50f-4584-9247-758ab488d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the 'dataid' column matches any value in RS_id_list\n",
    "merged_cat_wl = merged_cat_wl[~merged_cat_wl['objectId'].isin(RS_id_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538590f5-86e8-408d-8086-907d16dbeba4",
   "metadata": {},
   "source": [
    "## Lensing cuts\n",
    "\n",
    "The RS sequence has been removed. Now apply a series of lensing cuts (mostly following Shenming's [CLMM HSC demo analysis](https://github.com/LSSTDESC/CLMM/blob/main/examples/mass_fitting/Example4_Fit_Halo_mass_to_HSC_data.ipynb), but missing some at the moment), to the `merged_cat_wl` catalog. There might be more cuts to implement to improve sample purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aee903-ea0f-4006-8986-300b280eb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_cat_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55d85a-fd19-4fe6-b878-0daaeea4a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute again magnitudes, but for the RS-free catalog\n",
    "mag_i = -2.50 * np.log10(merged_cat_wl['i_cModelFlux']) + 31.4\n",
    "mag_r = -2.50 * np.log10(merged_cat_wl['r_cModelFlux']) + 31.4\n",
    "\n",
    "# Filters to keep sources with good-quality measured shape in i band\n",
    "source_filt = np.isfinite(merged_cat_wl['i_hsmShapeRegauss_e1'])\n",
    "source_filt &= np.isfinite(merged_cat_wl['i_hsmShapeRegauss_e2'])\n",
    "source_filt &= np.sqrt(merged_cat_wl['i_hsmShapeRegauss_e1']**2 + merged_cat_wl['i_hsmShapeRegauss_e2']**2) < 4\n",
    "source_filt &= merged_cat_wl['i_hsmShapeRegauss_sigma']<= 0.4 \n",
    "source_filt &= merged_cat_wl['i_hsmShapeRegauss_flag'] == 0\n",
    "source_filt &= merged_cat_wl['i_blendedness'] < 0.42\n",
    "source_filt &= merged_cat_wl['i_iPSF_flag']==0\n",
    "\n",
    "# Resolution factor quality cut - according to Mandelbaum (2018) paper:\n",
    "# \"we use the resolution factor R2 which is defined using the trace of the moment matrix of the PSF TP and \n",
    "# of the observed (PSF-convolved) galaxy image TI as: R2 = 1- TP/TI\"\n",
    "# Best guess to translate that in terms of ComCam objectTable catalog output...\n",
    "\n",
    "res = 1 - (merged_cat_wl['i_ixxPSF']+ merged_cat_wl['i_iyyPSF']) / (merged_cat_wl['i_ixx']+ merged_cat_wl['i_iyy'])\n",
    "source_filt &= res >= 0.3\n",
    "\n",
    "# NB: Resolution needs to be double checked. As pointed out by Anthony, \n",
    "# the 'ext_shapeHSM_HsmShapeRegauss_resolution' column exists in \n",
    "# the deepCoadd_obj 'meas' table  but not in the objectTable table. Would need a match between the two to\n",
    "# pull the resolution directly from the meas table rather than recomputing it here (comparing the two \n",
    "# would be a good check of whether the formula below is the right one to use). To be done/investigated.\n",
    "\n",
    "source_filt &= mag_i <= 24.5\n",
    "#source_filt &= mag_i > 20. # to remove the brightest objects that are likely foreground objects\n",
    "\n",
    "print(f'Source sample size: {np.sum(source_filt)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b041b07-feb2-4f79-8c26-dd0ac50af6d0",
   "metadata": {},
   "source": [
    "### Final source sample CMD, (ra,dec) distribution, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afff352-325d-4937-95f4-e7b67f769444",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r[source_filt], mag_r[source_filt]-mag_i[source_filt], marker='.', s=0.3) # all galaxies  \n",
    "ax.set_ylim([-1,2])\n",
    "ax.set_xlim([18,27])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9a61a-9fe0-415d-9f5d-a479d68b8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = merged_cat_wl['coord_ra'][source_filt]\n",
    "dec = merged_cat_wl['coord_dec'][source_filt]\n",
    "e1 = merged_cat_wl['i_hsmShapeRegauss_e1'][source_filt]\n",
    "e2 = merged_cat_wl['i_hsmShapeRegauss_e2'][source_filt]\n",
    "e_err = merged_cat_wl['i_hsmShapeRegauss_sigma'][source_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063095f-9f59-4af6-bd3e-90dd47f2959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ra, dec, marker='.', s=0.2)\n",
    "plt.scatter([ra_bcg], [dec_bcg], marker='+', s=100, color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93fb66-2d1b-49e4-8a61-d67942ef6b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:54:39.992227Z",
     "iopub.status.busy": "2025-02-27T15:54:39.991847Z",
     "iopub.status.idle": "2025-02-27T15:54:39.993946Z",
     "shell.execute_reply": "2025-02-27T15:54:39.993660Z",
     "shell.execute_reply.started": "2025-02-27T15:54:39.992214Z"
    }
   },
   "source": [
    "## Apply HSC shear calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c99a9-d60f-40c7-adbb-a2fdd0261f32",
   "metadata": {},
   "source": [
    "### Save source catalog `merged_cat_wl` as fits file to use as input for the HSC calibration script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee3b7a-16be-4ef1-be44-dd382ca44efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table, vstack\n",
    "import pandas as pd\n",
    "\n",
    "# Too many columns in the pandas dataframe. Remove some unecessary ones.\n",
    "import re\n",
    "# Define pattern (example: drop all columns starting with \"temp_\")\n",
    "pattern = r\"^g_|^z_\"  \n",
    "# Drop columns matching the pattern\n",
    "merged_cat_wl = merged_cat_wl.drop(columns=[col for col in merged_cat_wl.columns if re.match(pattern, col)])\n",
    "\n",
    "astropy_table = Table.from_pandas(merged_cat_wl[source_filt])\n",
    "astropy_table.write('source_sample.fits', format=\"fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678b645-c6a5-4bff-845b-8c87811d6a92",
   "metadata": {},
   "source": [
    "Now that the source_sample.fits file exists, need to use the HSC calibration in the command line. The `get_snr, get_res, get_psf_ellip` functions in the `utilities.py` file from the HSC calibration repo first need to be updated to use the column names of DP1. Then run:\n",
    "```\n",
    "python gen_hsc_calibrations.py source_sample.fits source_sample_calib.fits\n",
    "```\n",
    "which will create the `source_sample_calib.fits` file that is read below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b42c91-e617-459a-9fd2-9bcd873abe1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:50:49.871749Z",
     "iopub.status.busy": "2025-03-11T08:50:49.871448Z",
     "iopub.status.idle": "2025-03-11T08:50:49.873940Z",
     "shell.execute_reply": "2025-03-11T08:50:49.873606Z",
     "shell.execute_reply.started": "2025-03-11T08:50:49.871734Z"
    }
   },
   "source": [
    "### Read in the calibration quantities and apply the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8aeb9a-de58-4fca-88e0-dbf7486f3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table, vstack\n",
    "import pandas as pd\n",
    "\n",
    "with fits.open('source_sample_calib.fits') as hdul:\n",
    "    # Assuming data is in the first HDU (if not, change the index as needed)\n",
    "    data = hdul[1].data\n",
    "\n",
    "    # Convert the FITS data to an Astropy Table\n",
    "    table = Table(data)\n",
    "\n",
    "e_rms = table[\"ishape_hsm_regauss_derived_rms_e\"]\n",
    "m = table[\"ishape_hsm_regauss_derived_shear_bias_m\"]\n",
    "c1 = table[\"ishape_hsm_regauss_derived_shear_bias_c1\"]\n",
    "c2 = table[\"ishape_hsm_regauss_derived_shear_bias_c2\"]\n",
    "weight = table[\"ishape_hsm_regauss_derived_shape_weight\"]\n",
    "\n",
    "to_use = np.isfinite(weight)*np.isfinite(e_rms)*np.isfinite(m)*np.isfinite(c1)*np.isfinite(c2)\n",
    "\n",
    "e1_0 = e1[to_use]\n",
    "e2_0 = e2[to_use]\n",
    "e_rms = e_rms[to_use]\n",
    "c1 = c1[to_use]\n",
    "c2 = c2[to_use]\n",
    "m = m[to_use]\n",
    "weight = weight[to_use]\n",
    "\n",
    "print(f'Number of sources with calibration: {np.sum(to_use)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c3ff7-b4df-49ea-ba0b-f0adb93b564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Shenming's CLMM demo on using HSC data\n",
    "def apply_shear_calibration(e1_0, e2_0, e_rms, m, c1, c2, weight):\n",
    "    R = 1.0 - np.sum(weight * e_rms**2.0) / np.sum(weight)\n",
    "    m_mean = np.sum(weight * m) / np.sum(weight)\n",
    "    c1_mean = np.sum(weight * c1) / np.sum(weight)\n",
    "    c2_mean = np.sum(weight * c2) / np.sum(weight)\n",
    "    print(\"R, m_mean, c1_mean, c2_mean: \", R, m_mean, c1_mean, c2_mean)\n",
    "\n",
    "    g1 = (e1_0 / (2.0 * R) - c1) / (1.0 + m_mean)\n",
    "    g2 = (e2_0 / (2.0 * R) - c2) / (1.0 + m_mean)\n",
    "\n",
    "    return g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713af3e-07ce-4a4c-b758-059625117444",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1, g2 = apply_shear_calibration(e1_0, e2_0, e_rms, m, c1, c2, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f65e6-8be6-43af-b925-aa6fe7af5162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(e1[to_use], bins=100, alpha=0.2, range=[-2, 2], label='e1');\n",
    "plt.hist(g1, bins=100, alpha=0.2,range=[-2, 2], label='g1 - calibrated');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f38364-786a-43a2-ae1c-2d21785ed55b",
   "metadata": {},
   "source": [
    "## Mass Aperture Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894bd21-bfd7-497c-99ab-b8ec4f4011dd",
   "metadata": {},
   "source": [
    "Mass aperture statistics are one way of mapping the distribution of dark matter across a cluster, it's an integral statistic which convolves the observed shears with a filter optimized to match a given profile. For LoVoCCS (which I'll borrow here), we normally use a 'Schirmer filter' (Schirmer+04, Hetterscheidt+05, Schirmer+06, McCleary+18, Fu+22, Fu+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637bfb6-799b-4e15-8a08-02801eba2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schirmer_filter(radius,aperture_size=8000,x_cut=0.15,a=6,b=150,c=47,d=50,*_):\n",
    "    '''\n",
    "    The Schirmer Filter, a filter which is optimized for detecting NFW-like structures in shear-fields.\n",
    "    \n",
    "    Args:\n",
    "        radius: Numpy array; an array of radii to evaluate the filter on\n",
    "        aperture_size: float-like; the 'schirmer-radius' of the filter\n",
    "        x_cut: float-like; specifies the filter-sloap and sets the characteristic-scale of the filter to x_cut*smoothing\n",
    "    \n",
    "    Returns:\n",
    "        Q; Numpy array; an array containing the filter evaluated at each radius\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    x = radius/aperture_size\n",
    "    Q = ( 1/( 1 + np.exp(a - b*x) + np.exp(-c + d*x)) )*( np.tanh(x/x_cut)/(x/x_cut) )\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924383f-07c0-4fad-9661-73ad4d41ec7a",
   "metadata": {},
   "source": [
    "For the time being, I'll write this to work on a flat-sky approximation since we're only dealing with a ~0.5deg cutout surrounding the cluster. This uses a direct estimator for the aperture mass statistic at each point and evaluates it on a series of \"grid-points\" specified by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84e717-295a-42fc-8e2f-4f62d4082f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass_map(x_grid,y_grid,x,y,g1,g2,weights,q_filter,filter_kwargs={}):\n",
    "    '''\n",
    "    This function computes the mass aperture-statistics at each point on a specified grid. Run quality-cuts, NaN filtering, etc. before this step!\n",
    "    \n",
    "    Args:\n",
    "        x: Numpy array; an array of x-coordinates for each object\n",
    "        y: Numpy array; an array of y-coordinates for each object\n",
    "        x_grid: Numpy array; an NxM array of x-coordinates to sample the aperture-mass on\n",
    "        y_grid: Numpy array; an NxM array of y-coordinates to sample the aperture-mass on\n",
    "        g1; Numpy array; the shear g1 for each object\n",
    "        g2; Numpy array; the shear g2 for each object\n",
    "        weights: Numpy array; the weight for each object's shear\n",
    "        q_filter; function; the filter-function used to compute Map\n",
    "        kwargs; dict; kwargs passed to w_filter\n",
    "    \n",
    "    Returns:\n",
    "        Map_E: Numpy array; an NxM array containing the E-mode aperture mass evaluated at each grid-point\n",
    "        Map_B: Numpy array; an NxM array containing the B-mode aperture mass evaluated at each grid-point\n",
    "        Map_V: Numpy array; an NxM array containing the variance in the aperture mass evaluated at each grid-point\n",
    "\n",
    "    '''\n",
    "\n",
    "    y_shape = len(y_grid[:,0])\n",
    "    x_shape = len(x_grid[0,:])\n",
    "    \n",
    "    Map_E = np.zeros((y_shape,x_shape))\n",
    "    Map_B = np.zeros((y_shape,x_shape))\n",
    "    Map_V = np.zeros((y_shape,x_shape))\n",
    "    \n",
    "    if 'aperture_size' not in filter_kwargs:\n",
    "        filter_area = np.pi * (8000)**2\n",
    "    else:\n",
    "        filter_area = np.pi * filter_kwargs['aperture_size']**2\n",
    "    \n",
    "    # an extra catch for an objects assigned NaN g1/g2 just in case\n",
    "    nan_catch = np.isfinite(g1) & np.isfinite(g2)\n",
    "    x = x[nan_catch]\n",
    "    y = y[nan_catch]\n",
    "    g1 = g1[nan_catch]\n",
    "    g2 = g2[nan_catch]\n",
    "    weights = weights[nan_catch]\n",
    "    \n",
    "    for i in range(y_shape):\n",
    "        for j in range(x_shape):\n",
    "            delta_x = x_grid[j,i] - x\n",
    "            delta_y = y_grid[j,i] - y\n",
    "            radius = np.sqrt(delta_x**2 + delta_y**2)\n",
    "            theta = np.arctan2(delta_y,delta_x)\n",
    "            g_T = -g1*np.cos(2*theta) - g2*np.sin(2*theta)\n",
    "            g_X =  g1*np.sin(2*theta) - g2*np.cos(2*theta)\n",
    "            g_mag = g1**2 + g2**2\n",
    "            \n",
    "            filter_values = q_filter(radius,**filter_kwargs)\n",
    "\n",
    "            weight_sum = np.sum(weights)\n",
    "            \n",
    "            Map_E[i,j] = np.sum(filter_values*g_T*weights)*filter_area/weight_sum\n",
    "            Map_B[i,j] = np.sum(filter_values*g_X*weights)*filter_area/weight_sum\n",
    "            Map_V[i,j] = np.sum( (filter_values**2)*g_mag*(weights**2) )*(filter_area**2)/(2*(weight_sum**2))\n",
    "    \n",
    "    return Map_E, Map_B, Map_V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a3571-8a1b-4685-bb50-7798f1a5ac84",
   "metadata": {},
   "source": [
    "Let's define a grid of x and y coordinates from the catalog of selected galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fbd91-499f-405f-9462-bdca1ddb9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object positions\n",
    "x = merged_cat_wl['coord_ra'][source_filt][to_use]\n",
    "y = merged_cat_wl['coord_dec'][source_filt][to_use]\n",
    "\n",
    "# for now I'll weight everything uniformly\n",
    "weights = weight #np.ones(len(x))\n",
    "\n",
    "# Define an NxN grid centered on the cluster\n",
    "N = 151\n",
    "\n",
    "mid_x = ra_bcg\n",
    "mid_y = dec_bcg\n",
    "x_grid_samples = np.linspace(mid_x-0.5,mid_x+0.5,N)\n",
    "y_grid_samples = np.linspace(mid_y-0.5,mid_y+0.5,N)\n",
    "y_grid,x_grid = np.meshgrid(y_grid_samples,x_grid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b860c-5d75-4cfb-96f9-261e175773a7",
   "metadata": {},
   "source": [
    "Define a WCS for this grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be5387-35c2-464d-afdd-6786f5493a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wcs from astropy\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# build wcs centered on BCG\n",
    "Map_wcs = WCS(naxis=2)\n",
    "crval_sky = [ra_bcg*u.deg,dec_bcg*u.deg]\n",
    "Map_wcs.wcs.crval = [ra_bcg,dec_bcg]\n",
    "Map_wcs.wcs.crpix = [int(N/2),int(N/2)]\n",
    "Map_wcs.wcs.cdelt = [-1/N,1/N]\n",
    "Map_wcs.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n",
    "Map_wcs.wcs.radesys = 'ICRS'\n",
    "Map_wcs.wcs.equinox = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e15aa7-5753-4618-b112-597240a98808",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map_wcs.wcs.cd = [[-1/N,0],[0,1/N]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf555c48-1ec4-42ed-a775-0734795331f2",
   "metadata": {},
   "source": [
    "Now we're all set to compute the MassMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd2241-aa8d-4203-a9a3-b98b0702b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a minute to run\n",
    "e_ap,b_ap,v_ap = compute_mass_map(x_grid,y_grid,x,y,g1,g2,weights,schirmer_filter,filter_kwargs={'aperture_size':0.6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747d5b5-0f59-447a-b5a7-0bd64e815577",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2,subplot_kw=dict(projection=Map_wcs),figsize=(10,6))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_title('E-Mode SN')\n",
    "MapE = ax.imshow(e_ap/np.sqrt(v_ap),origin='lower',vmax=3,vmin=-2)\n",
    "\n",
    "lon = ax.coords[0]\n",
    "lat = ax.coords[1]\n",
    "\n",
    "lon.set_major_formatter('d.d')\n",
    "lat.set_major_formatter('d.d')\n",
    "lon.set_axislabel('RA')\n",
    "lat.set_axislabel('DEC')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('B-Mode SN')\n",
    "MapB = ax.imshow(b_ap/np.sqrt(v_ap),origin='lower',vmax=3,vmin=-2)\n",
    "\n",
    "lon = ax.coords[0]\n",
    "lat = ax.coords[1]\n",
    "\n",
    "lon.set_major_formatter('d.d')\n",
    "lat.set_major_formatter('d.d')\n",
    "lon.set_axislabel('')\n",
    "lat.set_axislabel('')\n",
    "\n",
    "cbar = fig.colorbar(MapE, ax=axs,fraction=0.025)\n",
    "\n",
    "#fig.savefig('ACO360_mass_map.png',dpi=480)\n",
    "# woohoo, we have a signal!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
